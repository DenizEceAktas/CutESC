{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "import kneed\n",
    "import networkx as netx\n",
    "from scipy.spatial import Delaunay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list filled with zeros as long as the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zerolist(n):\n",
    "    list_zero = [0] * n\n",
    "    return list_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the nodes,adjacency,edges and number of nodes attributes of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCompGraph(graph):\n",
    "    nodes = dict(graph.nodes())\n",
    "    adjacency = dict(graph.adjacency())\n",
    "    node_num = graph.number_of_nodes()\n",
    "    edges = dict(graph.edges())\n",
    "    return nodes, adjacency, edges, node_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the cutESC function that calls the other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutESC(data):\n",
    "    graph = DelaunayG(data)\n",
    "    gabriel(graph)\n",
    "    gloEdges(graph)\n",
    "    findLoc(graph)\n",
    "    findOtherLocal(graph)\n",
    "    label, Scc = assignClusterLabels(graph)\n",
    "    return label, Scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CutESC algorithm starts here and in the code below a spatial graph is generated using Delaunay graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DelaunayG(data):\n",
    "    tri = Delaunay(data, qhull_options='QJ Pp')  # delaunay generator\n",
    "    edges = []\n",
    "    for k in tri.simplices:\n",
    "        for indices in itertools.combinations(k, 2):\n",
    "            edges.append(indices)\n",
    "\n",
    "    graph = netx.Graph(edges)  # this is the edges(connnections)\n",
    "    nodes = dict(graph.nodes())\n",
    "    for i in nodes:\n",
    "        nodes[i]['node'] = np.array(data[i])\n",
    "    adjacency = dict(graph.adjacency())\n",
    "    removed = []\n",
    "    for i in nodes:\n",
    "        for j in adjacency[i]:\n",
    "            weight = np.linalg.norm(nodes[i]['node'] - nodes[j]['node'])\n",
    "            if weight != 0:\n",
    "                graph.edges[(i, j)]['weight'] = weight\n",
    "            else:\n",
    "                removed.append((i, j))\n",
    "    graph.remove_edges_from(removed)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the part that checks_edges for the pool function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_edge(i):\n",
    "    try:\n",
    "        removed_edges = []\n",
    "        for j in adjacencys[i]:\n",
    "            dist_ij = np.linalg.norm(node[i]['node'] - node[j]['node'])\n",
    "            for k in adjacencys[i]:\n",
    "                if j == k:\n",
    "                    continue\n",
    "                dist_ik = np.linalg.norm(node[i]['node'] - node[k]['node'])\n",
    "                dist_jk = np.linalg.norm(node[j]['node'] - node[k]['node'])\n",
    "                if dist_ij ** 2 > dist_ik ** 2 + dist_jk ** 2:\n",
    "                    removed_edges.append((i, j))\n",
    "                    break\n",
    "        return removed_edges\n",
    "    except Exception as e:\n",
    "        print('failed', flush=True)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gabriel graph function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriel(graph):\n",
    "    global node\n",
    "    global adjacencys\n",
    "    node = dict(graph.nodes())\n",
    "    adjacencys = dict(graph.adjacency())\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = mp.Pool(processes=mp.cpu_count() - 1)\n",
    "        removed_edges = pool.map(check_edge, node)\n",
    "        removed_edges = set(itertools.chain.from_iterable(removed_edges))\n",
    "        pool.close()\n",
    "        graph.remove_edges_from(removed_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this part of the graph globally long edges are found and removed from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gloEdges(graph):\n",
    "    nodes, adjacency, edges, node_num = findCompGraph(graph)\n",
    "    weights = list(netx.get_edge_attributes(graph, 'weight').values())\n",
    "    mean_loc = zerolist(node_num)\n",
    "\n",
    "    for i in nodes:  # the mean length of incident edges of vertex Pi\n",
    "        loc_m = 0\n",
    "        for j in adjacency[i]:\n",
    "            loc_m = loc_m + graph.edges[i, j][\"weight\"]\n",
    "        if len(adjacency[i]) == 0:\n",
    "            mean_loc[i] = loc_m  # mean(Pi)\n",
    "            continue\n",
    "        else:\n",
    "            loc_m = loc_m / len(adjacency[i])\n",
    "            mean_loc[i] = loc_m  # mean(Pi)\n",
    "\n",
    "    global_m = np.mean(weights)  # mean(GG)          #the mean length of all edges in gabriel graph\n",
    "    glo_std = 0\n",
    "\n",
    "    for i in nodes:  # the standard derivation of the mean length of edges in neigborhood\n",
    "        glo_std = glo_std + math.pow(global_m - mean_loc[i], 2)\n",
    "    glo_std = math.sqrt(glo_std / (node_num - 1))  # std(GG)\n",
    "    GCuti = list()  # cut edge value\n",
    "\n",
    "    for i in range(node_num):\n",
    "        if mean_loc[i] == 0:\n",
    "            GCuti.append(0)\n",
    "        else:\n",
    "            var = global_m * glo_std / mean_loc[i]\n",
    "            var = var + global_m\n",
    "            GCuti.append(var)\n",
    "\n",
    "    remove = list()  # remove globally long edges\n",
    "\n",
    "    for i in edges:\n",
    "        if (edges[i][\"weight\"] >= GCuti[i[0]]) or (edges[i][\"weight\"]) >= GCuti[i[1]]:\n",
    "            remove.append(i)\n",
    "    graph.remove_edges_from(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this part locally long edges found and removed from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLoc(graph):\n",
    "    graph_var = [var for var in sorted(\n",
    "        netx.connected_components(graph), key=len, reverse=True)]\n",
    "    label = zerolist(graph.number_of_nodes())\n",
    "    for i, var in enumerate(graph_var):\n",
    "        for j in var:\n",
    "            label[j] = i\n",
    "    nodes, adjacency, edges, node_num = findCompGraph(graph)\n",
    "    loc_st = zerolist(node_num)\n",
    "    graph_var_m = zerolist(len(graph_var))\n",
    "\n",
    "    for i in nodes:  # the mean length of edges in the second order neighborhood of a vertex Pi in a subgraph Gx\n",
    "        loc_m = 0\n",
    "        nei_num = 0\n",
    "        for j in adjacency[i]:\n",
    "            weight = graph.edges[i, j]['weight']\n",
    "            loc_m = loc_m + weight\n",
    "            nei_num = nei_num + 1\n",
    "            for n in adjacency[j]:\n",
    "                weight2 = graph.edges[j, n]['weight']\n",
    "                loc_m = loc_m + weight2\n",
    "                nei_num = nei_num + 1\n",
    "\n",
    "        if nei_num != 0:\n",
    "            loc_m = loc_m / nei_num\n",
    "        graph_var_m[label[i]] = loc_m + graph_var_m[label[i]]  # mean(Pi)\n",
    "\n",
    "    for i in range(len(graph_var_m)):\n",
    "        graph_var_m[i] = graph_var_m[i] / len(graph_var[i])  # mean(Gk)\n",
    "\n",
    "    for i in nodes:  # the standard derivation of all edges that are directly connected to vertex Pi\n",
    "        loc_std = 0\n",
    "        nei_num = 0\n",
    "        for j in adjacency[i]:\n",
    "            weight = graph.edges[i, j]['weight']\n",
    "            loc_std = loc_std + math.pow(graph_var_m[label[i]] - weight, 2)\n",
    "            nei_num = nei_num + 1\n",
    "            for n in adjacency[j]:\n",
    "                weight = graph.edges[j, n]['weight']\n",
    "                loc_std = loc_std + math.pow(graph_var_m[label[i]] - weight, 2)\n",
    "                nei_num = nei_num + 1\n",
    "        if nei_num != 0:\n",
    "            loc_std = math.sqrt(loc_std / (nei_num - 1))\n",
    "        loc_st[i] = loc_std  # std(Pi)\n",
    "\n",
    "    alpha = 1.0  # should be between 0 and 1 set to 1 by default\n",
    "    remove = list()  # remove part\n",
    "    for i in edges:\n",
    "        try:\n",
    "            val1 = math.exp(graph_var_m[label[i[0]]] / graph.edges[i]['weight'])\n",
    "            val1 = alpha * loc_st[i[0]] * val1\n",
    "            val1 = graph_var_m[label[i[0]]] + val1\n",
    "        except OverflowError:\n",
    "            val1 = float('inf')\n",
    "        try:\n",
    "            val2 = math.exp(graph_var_m[label[i[1]]] / graph.edges[i]['weight'])\n",
    "            val2 = alpha * loc_st[i[1]] * val2\n",
    "            val2 = graph_var_m[label[i[1]]] + val2\n",
    "        except OverflowError:\n",
    "            val2 = float('inf')\n",
    "        if (edges[i]['weight'] >= val1) or (edges[i]['weight'] >= val2):\n",
    "            remove.append(i)\n",
    "    graph.remove_edges_from(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section other locally long edges are identified and removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOtherLocal(graph, beta=1.0):\n",
    "    # finding other locally long edges\n",
    "    nodes, adjacency, edges, node_num = findCompGraph(graph)\n",
    "    loc_me = zerolist(node_num)\n",
    "    loc_st = zerolist(node_num)\n",
    "    for i in nodes:  # the mean length of edges in the second order neighborhood of a vertex Pi in a  new subgraph\n",
    "        loc_m = 0\n",
    "        nei_num = 0\n",
    "        for j in adjacency[i]:\n",
    "            weight = graph.edges[i, j]['weight']\n",
    "            loc_m = loc_m + weight\n",
    "            nei_num = nei_num + 1\n",
    "            for n in adjacency[j]:\n",
    "                weight = graph.edges[j, n]['weight']\n",
    "                loc_m = loc_m + weight\n",
    "                nei_num = nei_num + 1\n",
    "\n",
    "        if nei_num == 0:\n",
    "            nei_m = loc_m\n",
    "            loc_me[i] = nei_m  # mean(Pi)\n",
    "            continue\n",
    "        if nei_num != 0:\n",
    "            nei_m = loc_m / nei_num\n",
    "            loc_me[i] = nei_m  # mean(Pi)\n",
    "\n",
    "    for i in nodes:  # the standard derivation of all edges that are directly connected to vertex Pi\n",
    "        loc_std = 0\n",
    "        nei_num = 0\n",
    "        for j in adjacency[i]:\n",
    "            weight = graph.edges[i, j]['weight']\n",
    "            loc_std = loc_std + math.pow(loc_me[i] - weight, 2)\n",
    "            nei_num = nei_num + 1\n",
    "            for n in adjacency[j]:\n",
    "                weight = graph.edges[j, n]['weight']\n",
    "                loc_std = loc_std + math.pow(loc_me[i] - weight, 2)\n",
    "                nei_num = nei_num + 1\n",
    "\n",
    "        if nei_num == 0:\n",
    "            loc_st[i] = loc_std  # std(Pi)\n",
    "            continue\n",
    "        if nei_num != 0:\n",
    "            if nei_num != 1:\n",
    "                loc_std = math.sqrt(loc_std / (nei_num - 1))\n",
    "            loc_st[i] = loc_std  # std(Pi)\n",
    "\n",
    "    beta = 1  # should be between 0 and 1 set to 1 by default\n",
    "    remove = list()  # remove part\n",
    "    for i in edges:\n",
    "        try:\n",
    "            val1 = math.exp(loc_me[i[0]] / graph.edges[i]['weight'])\n",
    "            val1 = beta * loc_st[i[0]] * val1\n",
    "            val1 = loc_me[i[0]] + val1\n",
    "        except OverflowError:\n",
    "            val1 = float('inf')\n",
    "        try:\n",
    "            val2 = math.exp(loc_me[i[1]] / graph.edges[i]['weight'])\n",
    "            val2 = beta * loc_st[i[1]] * val2\n",
    "            val2 = loc_me[i[1]] + val2\n",
    "        except OverflowError:\n",
    "            val2 = float('inf')\n",
    "        if (edges[i]['weight'] >= val1) or (edges[i]['weight'] >= val2):\n",
    "            remove.append(i)\n",
    "    graph.remove_edges_from(remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The part below assigns labels to clusters by using elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignClusterLabels(graph):\n",
    "    num_node = graph.number_of_nodes()\n",
    "\n",
    "    Scc = [var for var in sorted(\n",
    "        netx.connected_components(graph), key=len, reverse=True)]\n",
    "    label = zerolist(num_node)\n",
    "    for i, var in enumerate(Scc):\n",
    "        for j in var:\n",
    "            label[j] = i # find strongly connected components in the graph and sort it by descending order\n",
    "\n",
    "\n",
    "    histog = [len(var) for var in Scc]  # finding number of vertices in each Scc connected components\n",
    "\n",
    "\n",
    "    lengl = len(histog)\n",
    "    leng = list(range(lengl))\n",
    "    knees = kneed.KneeLocator(leng, histog, S=1.0, curve=\"convex\", direction=\"decreasing\")\n",
    "    idx = knees.knee  # locate elbow points\n",
    "\n",
    "    for i, var in enumerate(Scc[idx:]):\n",
    "        for j in var:\n",
    "            label[j] = -1\n",
    "\n",
    "    label = np.array(label)\n",
    "    Scc = np.array(Scc)\n",
    "    return label, Scc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
