{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from stat import ST_DEV\n",
    "from sys import argv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import kneed\n",
    "import scipy as sp\n",
    "import scipy.spatial\n",
    "import scipy.sparse\n",
    "import networkx as netx\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infinite global value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greatest_value = -sys.maxsize - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear = lambda: os.system('clear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list filled with zeros as long as the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zerolist(n):\n",
    "    list_zero = [0] * n\n",
    "    return list_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the nodes,adjacency,edges and number of nodes attributes of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCompGraph(graph):\n",
    "    nodes = dict(graph.nodes())\n",
    "    adjacency = dict(graph.adjacency())\n",
    "    node_num = graph.number_of_nodes()\n",
    "    edges = dict(graph.edges())\n",
    "    return nodes, adjacency, edges, node_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CutESC algorithm starts here and in the code below a spatial graph is generated using Delaunay graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CutESC(data):\n",
    "    tri = sp.spatial.Delaunay(data)                   # delaunay generator\n",
    "    lil = sp.sparse.lil_matrix((tri.points, tri.points))     #turn the dealunay triangulars to matrix\n",
    "    indices, indptr = tri.vertex_neighbor_vertices\n",
    "    for k in range(tri.points):\n",
    "        lil.rows[k] = indptr[indices[k]:indices[k + 1]]\n",
    "        lil.data[k] = np.ones_like(lil.rows[k])               #example data of same shape as row that is filled with ones\n",
    "    coo = lil.tocoo()                             #coo format to access to each node edge node pair\n",
    "    conns = np.vstack((coo.row, coo.col)).T           #connections have two nodes at the ends of the edge\n",
    "    delaunay_conns = np.sort(conns, axis=1)              # this is the edges(delaunay connnections)\n",
    "    graph = netx.Graph(delaunay_conns)\n",
    "    nodes = dict(graph.nodes())\n",
    "    for i in nodes:\n",
    "        nodes[i]['node'] = np.array(data[i])             #add nodes\n",
    "    adjacency = dict(graph.adjacency())\n",
    "    removed = []\n",
    "    for i in nodes:                                      #add weights to nodes\n",
    "        for j in adjacency[i]:\n",
    "            weight = np.linalg.norm(nodes[i]['node'] - nodes[j]['node'])\n",
    "            if weight != 0:\n",
    "                graph.edges[(i, j)]['weight'] = weight\n",
    "            else:\n",
    "                removed.append((i, j))\n",
    "    graph.remove_edges_from(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this part of the code gabriel graph is formed from delaunay triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tree = scipy.spatial.cKDTree(data)\n",
    "    c = tri.points[delaunay_conns]            # center of each edge\n",
    "    m = (c[:, 0, :] + c[:, 1, :]) / 2            # midpoint of each edge\n",
    "    r = np.sqrt(np.sum((c[:, 0, :] - c[:, 1, :]) ** 2, axis=1)) / 2            # radius\n",
    "    n = tree.query(x=m, k=1)[0]                 #the closest point for each midpoint\n",
    "    if n >= r * 0.999:\n",
    "        g = n                         #closest point to midpoint is at a distance r, then it is a Gabriel edge\n",
    "    gabriel_conns = delaunay_conns[g]  # gabriel edges\n",
    "\n",
    "    graph2 = netx.Graph(gabriel_conns)\n",
    "    nodes2 = dict(graph2.nodes())\n",
    "    for i in nodes2:\n",
    "        nodes2[i]['node'] = np.array(data[i])       #add nodes\n",
    "    adjacency2 = dict(graph2.adjacency())\n",
    "    removed2 = []\n",
    "    for i in nodes2:                                  #add weights to nodes\n",
    "        for j in adjacency2[i]:\n",
    "            weight2 = np.linalg.norm(nodes2[i]['node'] - nodes2[j]['node'])\n",
    "            if weight2 != 0:\n",
    "                graph2.edges[(i, j)]['weight'] = weight2\n",
    "            else:\n",
    "                removed2.append((i, j))\n",
    "    graph2.remove_edges_from(removed2)\n",
    "    nodes2 = dict(graph2.nodes())\n",
    "    adjacency2 = dict(graph2.adjacency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this part of the graph globally long edges are found and removed from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gloEdges(graph):\n",
    "    nodes, adjacency, edges, node_num = findCompGraph(graph)\n",
    "    weights = list(netx.get_edge_attributes(graph, 'weight').values())\n",
    "    mean_loc = zerolist(node_num)\n",
    "\n",
    "    for i in nodes:  # the mean length of incident edges of vertex Pi\n",
    "        loc_m = 0\n",
    "        for j in adjacency[i]:\n",
    "            loc_m = loc_m + graph.edges[i, j][\"weight\"]\n",
    "        if len(adjacency[i]) == 0:\n",
    "            mean_loc[i] = loc_m  # mean(Pi)\n",
    "            continue\n",
    "        else:\n",
    "            loc_m = loc_m / len(adjacency[i])\n",
    "            mean_loc[i] = loc_m  # mean(Pi)\n",
    "\n",
    "    global_m = np.mean(weights)  # mean(GG)          #the mean length of all edges in gabriel graph\n",
    "    glo_std = 0\n",
    "\n",
    "    for i in nodes:  # the standard derivation of the mean length of edges in neigborhood\n",
    "        glo_std = glo_std + math.pow(global_m - mean_loc[i], 2)\n",
    "    glo_std = math.sqrt(glo_std / (node_num - 1))  # std(GG)\n",
    "    GCuti = list()  # cut edge value\n",
    "\n",
    "    for i in range(node_num):\n",
    "        if mean_loc[i] == 0:\n",
    "            GCuti.append(0)\n",
    "        else:\n",
    "            var = global_m * glo_std / mean_loc[i]\n",
    "            var = var + global_m\n",
    "            GCuti.append(var)\n",
    "\n",
    "    remove = list()  # remove globally long edges\n",
    "\n",
    "    for i in edges:\n",
    "        if (edges[i][\"weight\"] >= GCuti[i[0]]) or (edges[i][\"weight\"]) >= GCuti[i[1]]:\n",
    "            remove.append(i)\n",
    "    graph.remove_edges_from(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this part locally long edges found and removed from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLoc(graph):\n",
    "    nodes, adjacency, edges, node_num = findCompGraph(graph)\n",
    "    mean_loc = list()\n",
    "    loc_st = zerolist(node_num)\n",
    "    label = list()\n",
    "    graph_var = list()\n",
    "    for var in sorted(netx.connected_components(graph), reverse=True):\n",
    "        graph_var[var] = [var]\n",
    "    for i in range(len(graph_var)):\n",
    "        for j in graph_var[i]:\n",
    "            label.insert(j, i)\n",
    "    label = np.array(label)\n",
    "    graph_var_m = zerolist(len(graph_var))\n",
    "    nei_m = 0\n",
    "    for i in nodes:  # the mean length of edges in the second order neighborhood of a vertex Pi in a subgraph Gx\n",
    "        loc_m = 0\n",
    "        nei_num = 0\n",
    "        for j in adjacency[i]:\n",
    "            weight = graph.edges[i, j]['weight']\n",
    "            loc_m = loc_m + weight\n",
    "            nei_num = nei_num + 1\n",
    "            for n in adjacency[j]:\n",
    "                weight = graph.edges[j, n]['weight']\n",
    "                loc_m = loc_m + weight\n",
    "                nei_num = nei_num + 1\n",
    "\n",
    "        if nei_num == 0:\n",
    "            nei_m = loc_m\n",
    "            graph_var_m[label[i]] = nei_m + graph_var_m[label[i]]  # mean(Pi)\n",
    "            continue\n",
    "        if nei_num != 0:\n",
    "            nei_m = loc_m / nei_num\n",
    "            graph_var_m[label[i]] = nei_m + graph_var_m[label[i]]  # mean(Pi)\n",
    "\n",
    "    for i in range(len(graph_var_m)):\n",
    "        graph_var_m[i] = graph_var_m[i] / len(graph_var[i])  # mean(Gk)\n",
    "\n",
    "    for i in nodes:  # the standard derivation of all edges that are directly connected to vertex Pi\n",
    "        loc_std = 0\n",
    "        nei_num = 0\n",
    "        for j in adjacency[i]:\n",
    "            weight = graph.edges[i, j]['weight']\n",
    "            loc_std = loc_std + math.pow(graph_var_m[label[i]] - weight, 2)\n",
    "            nei_num = nei_num + 1\n",
    "            for n in adjacency[j]:\n",
    "                weight = graph.edges[j, n]['weight']\n",
    "                loc_std = loc_std + math.pow(graph_var_m[label[i]] - weight, 2)\n",
    "                nei_num = nei_num + 1\n",
    "\n",
    "        if nei_num == 0:\n",
    "            loc_st[i] = loc_std  # std(Pi)\n",
    "            continue\n",
    "        if nei_num != 0:\n",
    "            loc_std = math.sqrt(loc_std / (nei_num - 1))\n",
    "        loc_st[i] = loc_std  # std(Pi)\n",
    "\n",
    "    alpha = 1  # should be between 0 and 1 set to 1 by default\n",
    "    remove = list()  # remove part\n",
    "    for i in edges:\n",
    "        val1 = math.exp(graph_var_m[label[i[0]]] / graph.edges[i]['weight'])\n",
    "        val1 = alpha * loc_st[i[0]] * val1\n",
    "        val1 = graph_var_m[label[i[0]]] + val1\n",
    "        val2 = math.exp(graph_var_m[label[i[1]]] / graph.edges[i]['weight'])\n",
    "        val2 = alpha * loc_st[i[1]] * val2\n",
    "        val2 = graph_var_m[label[i[1]]] + val2\n",
    "        if (edges[i]['weight'] >= val1) or (edges[i]['weight'] >= val2):\n",
    "            remove.append(i)\n",
    "    graph.remove_edges_from(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section other locally long edges are identified and removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOtherLocal(graph):\n",
    "    # finding other locally long edges\n",
    "    nodes, adjacency, edges, node_num = findCompGraph(graph)\n",
    "    loc_me = zerolist(node_num)\n",
    "    loc_st = zerolist(node_num)\n",
    "    for i in nodes:  # the mean length of edges in the second order neighborhood of a vertex Pi in a  new subgraph\n",
    "        loc_m = 0\n",
    "        nei_num = 0\n",
    "        for j in adjacency[i]:\n",
    "            weight = graph.edges[i, j]['weight']\n",
    "            loc_m = loc_m + weight\n",
    "            nei_num = nei_num + 1\n",
    "            for n in adjacency[j]:\n",
    "                weight = graph.edges[j, n]['weight']\n",
    "                loc_m = loc_m + weight\n",
    "                nei_num = nei_num + 1\n",
    "\n",
    "        if nei_num == 0:\n",
    "            nei_m = loc_m\n",
    "            loc_me[i] = nei_m  # mean(Pi)\n",
    "            continue\n",
    "        if nei_num != 0:\n",
    "            nei_m = loc_m / nei_num\n",
    "            loc_me[i] = nei_m  # mean(Pi)\n",
    "\n",
    "    for i in nodes:  # the standard derivation of all edges that are directly connected to vertex Pi\n",
    "        loc_std = 0\n",
    "        nei_num = 0\n",
    "        for j in adjacency[i]:\n",
    "            weight = graph.edges[i, j]['weight']\n",
    "            loc_std = loc_std + math.pow(loc_me[i] - weight, 2)\n",
    "            nei_num = nei_num + 1\n",
    "            for n in adjacency[j]:\n",
    "                weight = graph.edges[j, n]['weight']\n",
    "                loc_std = loc_std + math.pow(loc_me[i] - weight, 2)\n",
    "                nei_num = nei_num + 1\n",
    "\n",
    "        if nei_num == 0:\n",
    "            loc_st[i] = loc_std  # std(Pi)\n",
    "            continue\n",
    "        if nei_num != 0:\n",
    "            if nei_num != 1:\n",
    "                loc_std = math.sqrt(loc_std / (nei_num - 1))\n",
    "            loc_st[i] = loc_std  # std(Pi)\n",
    "\n",
    "    beta = 1  # should be between 0 and 1 set to 1 by default\n",
    "    remove = list()  # remove part\n",
    "    for i in edges:\n",
    "        val1 = math.exp(loc_me[i[0]] / graph.edges[i]['weight'])\n",
    "        val1 = beta * loc_st[i[0]] * val1\n",
    "        val1 = loc_me[i[0]] + val1\n",
    "        val2 = math.exp(loc_me[i[1]] / graph.edges[i]['weight'])\n",
    "        val2 = beta * loc_st[i[1]] * val2\n",
    "        val2 = loc_me[i[1]] + val2\n",
    "        if (edges[i]['weight'] >= val1) or (edges[i]['weight'] >= val2):\n",
    "            remove.append(i)\n",
    "    graph.remove_edges_from(remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The part below assigns labels to clusters by using elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignClusterLabels(graph):\n",
    "    num_node = graph.number_of_nodes()\n",
    "    histog = list()\n",
    "    label = zerolist(num_node)\n",
    "    Scc = list()\n",
    "    i = 0\n",
    "    for var in sorted(netx.connected_components(graph), key=len, reverse=True):\n",
    "        Scc[i] = var\n",
    "        i = i + 1\n",
    "    for i in range(len(Scc)):\n",
    "        for j in Scc[i]:\n",
    "            label[j] = i  # find strongly connected components in the graph and sort it by descending order\n",
    "\n",
    "    for i in range(len(Scc)):  # finding number of vertices in each Scc connected components\n",
    "        histog.append(len(Scc[i]))\n",
    "    leng = len(histog)\n",
    "    leng = list(range(leng))\n",
    "    knees = kneed.KneeLocator(leng, histog, S=1.0, curve=\"convex\", direction=\"decreasing\")\n",
    "    idx = knees.knee  # locate elbow points\n",
    "\n",
    "    for i in range(idx, len(Scc)):\n",
    "        for j in Scc[i]:\n",
    "            label[j] = -1\n",
    "\n",
    "    label = np.array(label)\n",
    "    Scc = np.array(Scc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
